{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1Qu4k4Sa6OS0zLecMCBgo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlueStar198/Business-Intelligence/blob/main/exemplo_ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ETL: Phython"
      ],
      "metadata": {
        "id": "yJo8tileksAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Extração dos dados da filial 1 (CSV)\n",
        "vendas_filial1 = pd.read_csv('vendas_filial1.csv')\n",
        "\n",
        "# Extração dos dados da filial 2 (Excel)\n",
        "vendas_filial2 = pd.read_excel('vendas_filial2.xlsx')\n",
        "\n",
        "# Transformações\n",
        "# Podemos fazer transformações adicionais aqui, se necessário\n",
        "\n",
        "# Visualização dos dados\n",
        "print(\"Dados da Filial 1:\")\n",
        "print(vendas_filial1.head())\n",
        "print(\"\\nDados da Filial 2:\")\n",
        "print(vendas_filial2.head())"
      ],
      "metadata": {
        "id": "Ggw1hVdEVdnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformações dos dados: Calcular o valor total de vendas para cada filial\n",
        "vendas_filial1['Valor Total'] = vendas_filial1['Quantidade Vendida'] * vendas_filial1['Preço Unitário']\n",
        "vendas_filial2['Valor Total'] = vendas_filial2['Quantidade Vendida'] * vendas_filial2['Preço Unitário']\n",
        "\n",
        "#visualizar os dados transformados\n",
        "print(\"Dados transformados da Filial 1:\")\n",
        "print(vendas_filial1.head())\n",
        "print(\"\\nDados transformados da Filial 2:\")\n",
        "print(vendas_filial2.head())"
      ],
      "metadata": {
        "id": "FV9cbt8KaMsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregamento dos dados transformados para um arquivo CSV\n",
        "vendas_filial1.to_csv('vendas_filial1_transformadas.csv', index=False)\n",
        "vendas_filial2.to_csv('vendas_filial2_transformadas.csv', index=False)\n",
        "\n",
        "# Apresentar os dados carregados dos arquivos CSV\n",
        "dados_filial1 = pd.read_csv('vendas_filial1_transformadas.csv')\n",
        "dados_filial2 = pd.read_csv('vendas_filial2_transformadas.csv')\n",
        "\n",
        "print(\"Dados transformados da filial 1 (do arquivo CSV):\")\n",
        "print(dados_filial1.head())\n",
        "print(\"Dados transformados da filial 2 (do arquivo CSV):\")\n",
        "print(dados_filial2.head())"
      ],
      "metadata": {
        "id": "1w7mu6alfoFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Criar uma conexão com o banco de dados\n",
        "conn = sqlite3.connect('dados_transformados.db')\n",
        "\n",
        "# Carregar os dados transformados para tabelas SQL\n",
        "vendas_filial1.to_sql('vendas_filial1_transformadas', conn, index=False, if_exists='replace')\n",
        "vendas_filial2.to_sql('vendas_filial2_transformadas', conn, index=False, if_exists='replace')\n",
        "\n",
        "# Apresentar os dados carregados das tabelas SQL\n",
        "dados_filial1 = pd.read_sql('SELECT * FROM vendas_filial1_transformadas', conn)\n",
        "dados_filial2 = pd.read_sql('SELECT * FROM vendas_filial2_transformadas', conn)\n",
        "\n",
        "print(\"Dados transformados da filial 1 (do banco de dados SQL):\")\n",
        "print(dados_filial1.head())\n",
        "print(\"Dados transformados da filial 2 (do banco de dados SQL):\")\n",
        "print(dados_filial2.head())\n",
        "\n",
        "# Fechar a conexão com banco de dados\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "d9RQIifug-O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Criar uma conexão com o banco de dados\n",
        "conn = sqlite3.connect('dados_transformados.db')\n",
        "\n",
        "# Criar um cursor para executar consultas SQL\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Executar uma consulta SQL para obter os dados da tabela vendas_filial1_transformadas\n",
        "cursor.execute('SELECT * FROM vendas_filial1_transformadas')\n",
        "\n",
        "# Obter os resultados da consulta\n",
        "dados_filial1 = cursor.fetchall()\n",
        "\n",
        "#Exibir os dados da filial 1\n",
        "print(\"Dados transformados da filial 1:\")\n",
        "for linha in dados_filial1:\n",
        "  print(linha)\n",
        "\n",
        "# Executar uma consulta SQL para obter os dados da tabela vendas_filial2_transformadas\n",
        "cursor.execute('SELECT * FROM vendas_filial2_transformadas')\n",
        "\n",
        "# Obter os resultados da consulta\n",
        "dados_filial2 = cursor.fetchall()\n",
        "\n",
        "#Exibir os dados da filial 2\n",
        "print(\"Dados transformados da filial 2:\")\n",
        "for linha in dados_filial2:\n",
        "  print(linha)\n",
        "\n",
        "# Fechar a conexão com banco de dados\n",
        "cursor.close()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "2bNDYf_MiotV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA WAREHOUSE EXEMPLO 1\n"
      ],
      "metadata": {
        "id": "SioooGKik4m7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb1XJraOs3Q8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#\n",
        "num_produtos = 600\n",
        "produtos = {\n",
        "    'produto_id': range(1, num_produtos + 1),\n",
        "    'nome': [f'Produto {i}' for i in range(1, num_produtos + 1)],\n",
        "    'categoria': np.random.choice(['Eletrônicos', 'Roupas', 'Alimentos'], num_produtos)\n",
        "}\n",
        "\n",
        "#\n",
        "df_produtos = pd.DataFrame(produtos)\n",
        "\n",
        "#\n",
        "num_vendas = 1000 #\n",
        "data_vendas = {\n",
        "    'data': np.random.choice(pd.date_range('2024-04-10', periods=30), num_vendas), #\n",
        "    'produto_id': np.random.randint(1, num_produtos + 1, num_vendas),\n",
        "    'quantidade': np.random.randint(50, 200, num_vendas), #\n",
        "    'valor_total': np.random.randint(1000, 10000, num_vendas) #\n",
        "}\n",
        "\n",
        "#\n",
        "df_vendas = pd.DataFrame(data_vendas)\n",
        "\n",
        "#\n",
        "df_vendas.to_csv('vendas.csv', index=False)\n",
        "df_produtos.to_csv('produtos.csv', index=False)\n",
        "\n",
        "#\n",
        "df_vendas = pd.read_csv('vendas.csv')\n",
        "df_produtos = pd.read_csv('produtos.csv')\n",
        "\n",
        "#\n",
        "df_merge = pd.merge(df_vendas, df_produtos, on='produto_id', how='inner')\n",
        "\n",
        "#\n",
        "df_merge.to_csv('data_warehouse.csv', index=False)\n",
        "\n",
        "#\n",
        "df_warehouse = pd.read_csv('data_warehouse.csv')\n",
        "print(\"Conteudo do Data Warehouse:\")\n",
        "print(df_warehouse)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA WAREHOUSE EXEMPLO 2\n"
      ],
      "metadata": {
        "id": "lXcZJy9mlHjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#\n",
        "df_warehouse = pd.read_csv('data_warehouse.csv')\n",
        "\n",
        "\n",
        "#\n",
        "vendas_por_produto = df_warehouse.groupby('nome')[['quantidade','valor_total']].sum()\n",
        "print(\"Análise de vendas por produto:\")\n",
        "print(vendas_por_produto)\n",
        "\n",
        "#\n",
        "vendas_por_categoria = df_warehouse.groupby('categoria')[['quantidade','valor_total']].sum()\n",
        "print(\"\\nAnálise de vendas por categoria de produto:\")\n",
        "print(vendas_por_categoria)\n",
        "\n",
        "#\n",
        "df_warehouse['data'] = pd.to_datetime(df_warehouse['data'])\n",
        "vendas_por_data = df_warehouse.groupby('data')[['quantidade', 'valor_total']].sum()\n",
        "print(\"\\nAnalise de tendencias temporais:\")\n",
        "print(vendas_por_data)\n",
        "\n",
        "#\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(vendas_por_data.index, vendas_por_data['quantidade'], marker='o', linestyle='-')\n",
        "plt.title('vendas ao longo do tempo')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Quantidade vendida')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#\n",
        "desempenho_produto = df_warehouse.groupby('nome')['valor_total'].sum()\n",
        "print(\"\\nAnalise de desempenho de produtos:\")\n",
        "print(desempenho_produto)"
      ],
      "metadata": {
        "id": "0FbW-6gEI2K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATALAKE EXEMPLO 1\n"
      ],
      "metadata": {
        "id": "9EcbshDZlRZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#\n",
        "if not os.path.exists('data_lake'):\n",
        "  os.makedirs('data_lake')\n",
        "\n",
        "#\n",
        "num_files = 10\n",
        "num_rows_per_file = 1000\n",
        "\n",
        "#\n",
        "dfs = []\n",
        "\n",
        "#\n",
        "for i in range(num_files):\n",
        "  #\n",
        "  data = {\n",
        "      'coluna1': np.random.randint(0, 100, num_rows_per_file),\n",
        "      'coluna2': np.random.randn(num_rows_per_file),\n",
        "      'coluna3': np.random.choice(['A','B','C'], num_rows_per_file)\n",
        "  }\n",
        "\n",
        "#\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "#\n",
        "file_name = f'data_lake/dados_{i+1}.csv'\n",
        "df.to_csv(file_name, index=False)\n",
        "\n",
        "#\n",
        "dfs.append((file_name, df))\n",
        "\n",
        "print(\"Dados do Data Lake gerados com sucesso!\")\n",
        "\n",
        "#\n",
        "for file_name, df in dfs:\n",
        "  print(f\"\\nDados do arquivo: {file_name}\\n\")\n",
        "  print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waTli-aVlYik",
        "outputId": "758a5b50-d97e-4b26-cd6a-44749153217f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados do Data Lake gerados com sucesso!\n",
            "\n",
            "Dados do arquivo: data_lake/dados_10.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       36 -0.690935       B\n",
            "1       61  0.007202       B\n",
            "2       40 -0.501665       C\n",
            "3       61 -0.511890       A\n",
            "4       77  1.186259       C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATALAKE EXEMPLO 2\n"
      ],
      "metadata": {
        "id": "zGEdSxg0nx_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "#\n",
        "conn_string = 'sqlite:///data_lake.db'\n",
        "engine = create_engine(conn_string)\n",
        "\n",
        "#\n",
        "table_name = 'dados_1'  # Esta nomeando a tabela como dados_1\n",
        "df = pd.read_sql_table(table_name, engine)\n",
        "\n",
        "#\n",
        "print(\"Primeiras linhas do Data Frame:\")\n",
        "print(df.head())\n",
        "\n",
        "#\n",
        "print(\"\\nInformações sobre o Data Frame:\")\n",
        "print(df.info())\n",
        "\n",
        "#\n",
        "print(\"\\n Resumo estatístico do Data Frame:\")\n",
        "print(df.describe())\n",
        "\n",
        "#\n",
        "#\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='coluna1', y='coluna2', data=df)\n",
        "plt.title('Grafico de Dispersão entre coluna1 e coluna2')\n",
        "plt.xlabel('coluna1')\n",
        "plt.ylabel('coluna2')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='coluna1', bins=20, kde=True)\n",
        "plt.title('Histograma da coluna1')\n",
        "plt.xlabel('coluna1')\n",
        "plt.ylabel('Frequência')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='coluna3', y='coluna1', data=df)\n",
        "plt.title('Boxplot da coluna3 em relação à coluna1')\n",
        "plt.xlabel('coluna3')\n",
        "plt.ylabel('coluna1')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SI4M_Et2n0dM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}