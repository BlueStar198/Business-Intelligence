{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrU9GXlbWAa3cHV2t8xWMG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlueStar198/Business-Intelligence/blob/main/exemplo_ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ETL: Phython"
      ],
      "metadata": {
        "id": "yJo8tileksAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Extração dos dados da filial 1 (CSV)\n",
        "vendas_filial1 = pd.read_csv('vendas_filial1.csv')\n",
        "\n",
        "# Extração dos dados da filial 2 (Excel)\n",
        "vendas_filial2 = pd.read_excel('vendas_filial2.xlsx')\n",
        "\n",
        "# Transformações\n",
        "# Podemos fazer transformações adicionais aqui, se necessário\n",
        "\n",
        "# Visualização dos dados\n",
        "print(\"Dados da Filial 1:\")\n",
        "print(vendas_filial1.head())\n",
        "print(\"\\nDados da Filial 2:\")\n",
        "print(vendas_filial2.head())"
      ],
      "metadata": {
        "id": "Ggw1hVdEVdnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformações dos dados: Calcular o valor total de vendas para cada filial\n",
        "vendas_filial1['Valor Total'] = vendas_filial1['Quantidade Vendida'] * vendas_filial1['Preço Unitário']\n",
        "vendas_filial2['Valor Total'] = vendas_filial2['Quantidade Vendida'] * vendas_filial2['Preço Unitário']\n",
        "\n",
        "#visualizar os dados transformados\n",
        "print(\"Dados transformados da Filial 1:\")\n",
        "print(vendas_filial1.head())\n",
        "print(\"\\nDados transformados da Filial 2:\")\n",
        "print(vendas_filial2.head())"
      ],
      "metadata": {
        "id": "FV9cbt8KaMsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregamento dos dados transformados para um arquivo CSV\n",
        "vendas_filial1.to_csv('vendas_filial1_transformadas.csv', index=False)\n",
        "vendas_filial2.to_csv('vendas_filial2_transformadas.csv', index=False)\n",
        "\n",
        "# Apresentar os dados carregados dos arquivos CSV\n",
        "dados_filial1 = pd.read_csv('vendas_filial1_transformadas.csv')\n",
        "dados_filial2 = pd.read_csv('vendas_filial2_transformadas.csv')\n",
        "\n",
        "print(\"Dados transformados da filial 1 (do arquivo CSV):\")\n",
        "print(dados_filial1.head())\n",
        "print(\"Dados transformados da filial 2 (do arquivo CSV):\")\n",
        "print(dados_filial2.head())"
      ],
      "metadata": {
        "id": "1w7mu6alfoFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Criar uma conexão com o banco de dados\n",
        "conn = sqlite3.connect('dados_transformados.db')\n",
        "\n",
        "# Carregar os dados transformados para tabelas SQL\n",
        "vendas_filial1.to_sql('vendas_filial1_transformadas', conn, index=False, if_exists='replace')\n",
        "vendas_filial2.to_sql('vendas_filial2_transformadas', conn, index=False, if_exists='replace')\n",
        "\n",
        "# Apresentar os dados carregados das tabelas SQL\n",
        "dados_filial1 = pd.read_sql('SELECT * FROM vendas_filial1_transformadas', conn)\n",
        "dados_filial2 = pd.read_sql('SELECT * FROM vendas_filial2_transformadas', conn)\n",
        "\n",
        "print(\"Dados transformados da filial 1 (do banco de dados SQL):\")\n",
        "print(dados_filial1.head())\n",
        "print(\"Dados transformados da filial 2 (do banco de dados SQL):\")\n",
        "print(dados_filial2.head())\n",
        "\n",
        "# Fechar a conexão com banco de dados\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "d9RQIifug-O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Criar uma conexão com o banco de dados\n",
        "conn = sqlite3.connect('dados_transformados.db')\n",
        "\n",
        "# Criar um cursor para executar consultas SQL\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Executar uma consulta SQL para obter os dados da tabela vendas_filial1_transformadas\n",
        "cursor.execute('SELECT * FROM vendas_filial1_transformadas')\n",
        "\n",
        "# Obter os resultados da consulta\n",
        "dados_filial1 = cursor.fetchall()\n",
        "\n",
        "#Exibir os dados da filial 1\n",
        "print(\"Dados transformados da filial 1:\")\n",
        "for linha in dados_filial1:\n",
        "  print(linha)\n",
        "\n",
        "# Executar uma consulta SQL para obter os dados da tabela vendas_filial2_transformadas\n",
        "cursor.execute('SELECT * FROM vendas_filial2_transformadas')\n",
        "\n",
        "# Obter os resultados da consulta\n",
        "dados_filial2 = cursor.fetchall()\n",
        "\n",
        "#Exibir os dados da filial 2\n",
        "print(\"Dados transformados da filial 2:\")\n",
        "for linha in dados_filial2:\n",
        "  print(linha)\n",
        "\n",
        "# Fechar a conexão com banco de dados\n",
        "cursor.close()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "2bNDYf_MiotV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA WAREHOUSE EXEMPLO 1\n"
      ],
      "metadata": {
        "id": "SioooGKik4m7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb1XJraOs3Q8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Esta definindo número de produtos como 600 e em baixo esta criando informacoes sobre os produtos colocando ID, nome e categoria\n",
        "num_produtos = 600\n",
        "produtos = {\n",
        "    'produto_id': range(1, num_produtos + 1),\n",
        "    'nome': [f'Produto {i}' for i in range(1, num_produtos + 1)],\n",
        "    'categoria': np.random.choice(['Eletrônicos', 'Roupas', 'Alimentos'], num_produtos)\n",
        "}\n",
        "\n",
        "# Os dados dos produtos sao colocado como DataFrame dos Produtos\n",
        "df_produtos = pd.DataFrame(produtos)\n",
        "\n",
        "# Esta definindo número de vendas como 1000 e em baixo esta criando informacoes sobre as vendas colocando data, ID, quantidade e valorTotal\n",
        "num_vendas = 1000\n",
        "data_vendas = {\n",
        "    'data': np.random.choice(pd.date_range('2024-04-10', periods=30), num_vendas),  # Gera aleatoriamente os periodos entre a data de 10 de abril de 2024\n",
        "    'produto_id': np.random.randint(1, num_produtos + 1, num_vendas),  # Gera IDs de produtos aleatórios dentro do intervalo definido\n",
        "    'quantidade': np.random.randint(50, 200, num_vendas),  # Gera quantidades aleatórias de produtos vendidos\n",
        "    'valor_total': np.random.randint(1000, 10000, num_vendas)  # Gera valores totais aleatórios para as vendas\n",
        "}\n",
        "\n",
        "# Os dados das vendas sao colocado como DataFrame das Vendas\n",
        "df_vendas = pd.DataFrame(data_vendas)\n",
        "\n",
        "# Salva os dados das vendas e produtos em arquivos CSV\n",
        "df_vendas.to_csv('vendas.csv', index=False)\n",
        "df_produtos.to_csv('produtos.csv', index=False)\n",
        "\n",
        "# Coloca os arquivos CSV para ser lido em python\n",
        "df_vendas = pd.read_csv('vendas.csv')\n",
        "df_produtos = pd.read_csv('produtos.csv')\n",
        "\n",
        "# Junta os dados transformados de vendas e produtos com base no ID do produto\n",
        "df_merge = pd.merge(df_vendas, df_produtos, on='produto_id', how='inner')\n",
        "\n",
        "# Salva os dados juntados acima em um arquivo CSV, que representa o data warehouse\n",
        "df_merge.to_csv('data_warehouse.csv', index=False)\n",
        "\n",
        "# Faz a leitura do arquivo CSV do data warehouse para exibir seu conteúdo\n",
        "df_warehouse = pd.read_csv('data_warehouse.csv')\n",
        "print(\"Conteudo do Data Warehouse:\")\n",
        "print(df_warehouse)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA WAREHOUSE EXEMPLO 2\n"
      ],
      "metadata": {
        "id": "lXcZJy9mlHjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Lê os dados do data warehouse do arquivo CSV criado acima.\n",
        "df_warehouse = pd.read_csv('data_warehouse.csv')\n",
        "\n",
        "# Agrupa e mostra como \"Análise de vendas por produto:\" das vendas por nome do produto e soma as quantidades e valores totais vendidos de cada produto.\n",
        "vendas_por_produto = df_warehouse.groupby('nome')[['quantidade','valor_total']].sum()\n",
        "print(\"Análise de vendas por produto:\")\n",
        "print(vendas_por_produto)\n",
        "\n",
        "# Agrupa e mostra como \"Análise de vendas por categoria de produto:\" das vendas por categoria de produto e soma as quantidades e valores totais vendidos de cada categoria.\n",
        "vendas_por_categoria = df_warehouse.groupby('categoria')[['quantidade','valor_total']].sum()\n",
        "print(\"\\nAnálise de vendas por categoria de produto:\")\n",
        "print(vendas_por_categoria)\n",
        "\n",
        "# Converte a coluna de data para o tipo datetime.\n",
        "df_warehouse['data'] = pd.to_datetime(df_warehouse['data'])\n",
        "\n",
        "# Agrupa e mostra como \"Analise de tendencias temporais:\" das vendas por data e soma as quantidades e valores totais vendidos de cada dia.\n",
        "vendas_por_data = df_warehouse.groupby('data')[['quantidade', 'valor_total']].sum()\n",
        "print(\"\\nAnalise de tendencias temporais:\")\n",
        "print(vendas_por_data)\n",
        "\n",
        "# Cria um gráfico de linha mostrando as vendas ao longo do tempo.\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(vendas_por_data.index, vendas_por_data['quantidade'], marker='o', linestyle='-')\n",
        "plt.title('vendas ao longo do tempo')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Quantidade vendida')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Calcula e mostra o desempenho de cada um produtos somando o valor total das vendas de cada um.\n",
        "desempenho_produto = df_warehouse.groupby('nome')['valor_total'].sum()\n",
        "print(\"\\nAnalise de desempenho de produtos:\")\n",
        "print(desempenho_produto)\n"
      ],
      "metadata": {
        "id": "0FbW-6gEI2K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATALAKE EXEMPLO 1\n"
      ],
      "metadata": {
        "id": "9EcbshDZlRZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Se nao existe a pasta 'data_lake' no diretorio cria essa pasta.\n",
        "if not os.path.exists('data_lake'):\n",
        "  os.makedirs('data_lake')\n",
        "\n",
        "# Vai gerar 10 arquivos.\n",
        "num_files = 10\n",
        "# Tera 1000 linhas por arquivo.\n",
        "num_rows_per_file = 1000\n",
        "\n",
        "# Lista para armazenar os DataFrames e nomes dos arquivos.\n",
        "dfs = []\n",
        "\n",
        "# Loop para gerar dados e salvar em arquivos CSV.\n",
        "for i in range(num_files):\n",
        "  # Gera dados aleatórios para cada arquivo.\n",
        "  data = {\n",
        "      'coluna1': np.random.randint(0, 100, num_rows_per_file),\n",
        "      'coluna2': np.random.randn(num_rows_per_file),\n",
        "      'coluna3': np.random.choice(['A','B','C'], num_rows_per_file)\n",
        "  }\n",
        "\n",
        "  # Cria um DataFrame a partir dos dados gerados.\n",
        "  df = pd.DataFrame(data)\n",
        "\n",
        "  # Define o nome do arquivo usando o número do loop.\n",
        "  file_name = f'data_lake/dados_{i+1}.csv'\n",
        "\n",
        "  # Salva o DataFrame no arquivo CSV.\n",
        "  df.to_csv(file_name, index=False)\n",
        "\n",
        "  # Adiciona o nome do arquivo e o DataFrame à lista 'dfs'.\n",
        "  dfs.append((file_name, df))\n",
        "\n",
        "# Mensagem de confirmação após a geração dos dados.\n",
        "print(\"Dados do Data Lake gerados com sucesso!\")\n",
        "\n",
        "# Loop para imprimir os cinco primeiros registros de cada DataFrame.\n",
        "for file_name, df in dfs:\n",
        "  print(f\"\\nDados do arquivo: {file_name}\\n\")\n",
        "  print(df.head())\n"
      ],
      "metadata": {
        "id": "waTli-aVlYik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATALAKE EXEMPLO 2\n"
      ],
      "metadata": {
        "id": "zGEdSxg0nx_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "#Cria String de conexão (conn) com o banco de dados SQLite.\n",
        "conn_string = 'sqlite:///data_lake.db'\n",
        "engine = create_engine(conn_string)\n",
        "\n",
        "#Esta nomeando a tabela como dados_1 e lê os dados da tabela do banco de dados e carrega em DataFrame.\n",
        "table_name = 'dados_1'\n",
        "df = pd.read_sql_table(table_name, engine)\n",
        "\n",
        "#Exibe primeiras linhas do Data Frame\n",
        "print(\"Primeiras linhas do Data Frame:\")\n",
        "print(df.head())\n",
        "\n",
        "#Exibe informações sobre o DataFrame\n",
        "print(\"\\nInformações sobre o Data Frame:\")\n",
        "print(df.info())\n",
        "\n",
        "#Exibe um resumo estatístico do DataFrame\n",
        "print(\"\\n Resumo estatístico do Data Frame:\")\n",
        "print(df.describe())\n",
        "\n",
        "#Cria e exibe o gráfico de dispersão entre as colunas 'coluna1' e 'coluna2'.\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='coluna1', y='coluna2', data=df)\n",
        "plt.title('Grafico de Dispersão entre coluna1 e coluna2')\n",
        "plt.xlabel('coluna1')\n",
        "plt.ylabel('coluna2')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#Cria e exibe o histograma da coluna 'coluna1'.\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='coluna1', bins=20, kde=True)\n",
        "plt.title('Histograma da coluna1')\n",
        "plt.xlabel('coluna1')\n",
        "plt.ylabel('Frequência')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#Cria e exibe o boxplot da coluna 'coluna3' em relação à coluna 'coluna1'.\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='coluna3', y='coluna1', data=df)\n",
        "plt.title('Boxplot da coluna3 em relação à coluna1')\n",
        "plt.xlabel('coluna3')\n",
        "plt.ylabel('coluna1')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SI4M_Et2n0dM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}